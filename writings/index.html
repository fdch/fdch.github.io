<!doctype html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>Federico Camara Halac - Writings</title>
    <style>
      body {
        margin: 0;
        max-width: 60ch;
        margin: 0 auto;
        padding: 1rem;
      }
    </style>
  </head>
  <body>
    <header id="title-block-header">
      <h1 class="title">Federico Camara Halac - Writings</h1>
      <p class="subtitle">Push those keys</p>
      <nav><a href="/">home</a></nav>
    </header>
    <main>
      <p>
        <a href="http://icmpc.org/icmpcprograms/icmpc16_2021program.pdf"
          >visual cues as an aid in the auditory stream segregation of music</a
        >
        09.28.2021 2nd author. icmpc-escom2021 (proceedings, not published)
      </p>
      <p>
        <a href="https://dl.acm.org/doi/10.1145/3465616"
          >the woods: a mixed reality two-player cooperative game</a
        >
        08.09.2021. siggraph 2021 - published on the acm digital library
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          while loneliness in our real lives is increasingly recognized as
          having dire physical, mental and emotional consequences, cooperative
          games have been shown to build empathy and provide positive social
          impact. in this paper, we present “the woods”, a local cooperative
          mixed reality game that provides players with face-to-face
          interactions in pursuit of a shared goal using augmented reality and
          4-channel audio spatialization panning. this paper discusses the
          narrative, mechanical, and sonic components of the game, as well as
          its development process and the player experience. the goal of our
          team is to develop a narrative driven ar game that promotes
          collaborative problem-solving and engages players in an emergent
          physical and digital experience.
        </p>
      </details>
      <p>
        <a href="https://smartech.gatech.edu/handle/1853/66336"
          >dreamsound: deep activation layer sonification. 07.25.2021. federico
          camara halac and matias delgadino. international community for
          auditory displays</a
        >
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          deep learning in raw audio-based musical contexts is yet a largely
          unexplored field. in visual arts, the deep dream collective project
          utilizes deep convolutional neural network classifiers to generate
          self-refferential surreal images. in this paper, we present an
          adaptation of the deep dream project into an audio-based musical
          context. we created a rapid prototype by sonifying the activation
          layers of a pre-trained classifier, yamnet. to deal with noisy outputs
          we implemented fft filters supported on the frequencies of the
          original or a target audio.
        </p>
      </details>
      <p>
        comparing musical performances of the ‘goldberg variations’ using
        supervised machine learning techniques. 02.12.2021. 4th author. fdmc
        2020 (accepted but not presented)
      </p>
      <p>
        clone fd_dacout: real-time massively multichannel spatialization in pure
        data. 03.05.2020. international congress “sound spaces”, 23rd conference
        on computer and electronic music - jiem 2020. jiem-espacios sonoros 2020
        (lecture, not published)
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          this paper describes and discusses several approaches to working with
          massively multichannel music live using pure data. traditionally, most
          computer music works have had a tendency towards fixed media due to
          its stability and robustness when it comes to performance. likewise,
          the spatialization paradigm that has governed most electronic music
          continues to be stereo, with the use of diffusion or ambisonics as
          last resort spatialization techniques. emphasizing the importance of
          space, this paper describes the design of a real-time computer music
          piece called lorenz variations, written directly for high density
          loudspeaker arrays (hdlas) of variable lengths. in using point-source
          location techniques and vector-based amplitude panning (vbap) as
          composing tools instead of spatialization tools, i argue that space is
          not just a musical parameter but a compositional source that expands
          our listening experience into yet unknown dimensions, and it is our
          duty to explore the many aesthetic potentials it advances.
        </p>
      </details>
      <p>
        pathosonic: performing sound in virtual reality feature space.
        01.24.2020.
        <a href="https://doi.org/10.5281/zenodo.4813510"
          >nime 2020 proceedings</a
        >
        -
        <a href="https://fdch.github.io/pathosonic/poster">poster</a>
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          pathosonic is a virtual reality (vr) experience that enables a
          participant to visualize and perform a sound file based on timbre
          feature descriptors displayed in space. the name comes from the
          different paths the participant can create through their sonic
          explorations. the goal of this research is to leverage affordances of
          virtual reality technology to visualize sound through different levels
          of performance-based interactivity that immerses the participant’s
          body in a spatial virtual environment. through implementation of a
          multi-sensory experience, including visual aesthetics, sound, and
          haptic feedback, we explore inclusive approaches to sound
          visualization, making it more accessible to a wider audience including
          those with hearing, and mobility impairments.
        </p>
      </details>
      <p>
        <a href="https://fdch.github.io/database_music/output/main.pdf"
          >database music: a history, technology, and aesthetics of the database
          in music composition (5/6/2019)</a
        >
        - phd dissertation (nyu) -
        <a href="https://fdch.github.io/database_music">code</a>
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          the aim of this dissertation is to outline a framework to discuss the
          aesthetic agency of the database in music composition. i place my
          dissertation in relation to existing scholarship, artists, and
          developers working in the fields of music composition, computer
          science, affect, and ontology, with emphasis on the ubiquity of
          databases and on the need to reflect on their practice, particularly
          in relation to databasing and music composition. there is a database
          everywhere, anytime, always already affecting our lives; it is an
          agent in our aesthetic and political lives just as much as we are
          agents in its composition and performance. database music lives in
          between computers and sound.
        </p>
      </details>
      <p>
        <a href="/writing/waves.pdf"
          >composing database: opening a space for the concept of an anarchic
          unwork of art. 2018</a
        >
        - delian academy for new music 2018 (lecture)
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          the practice of composition takes place from the most distant memory
          of sound to the intimacy of perceivable waves. for music to emerge
          from these waves, two negative processes need to take place, relating
          to consciousness, memory, and difference. these constitute the
          possibility condition of what i call the unveiling, staging, and
          unworking of the music object. from this rethinking of the composition
          practice, how does identity emerge from this precondition of
          difference? this is how the database enters into this framing of the
          practice of composition. drawing from derrida’s conceptualization of
          the archive, i find the ‘archontic’ principle embedded within the
          structural quality of the database, and emerging through its
          performance. the computer is a multitude of databases constantly
          projecting their authority, their archontic power onto their users.
          thus, in the same way the written word becomes the rule, just as the
          structured data prescribes its command, the severed object of music
          emerges as style, order, or identity. the question is, however, how
          can we conceive the aesthetic experience without this authoritative
          character; without this inherent imposition of order and identity? the
          space is opened, thus, for the concept of an anarchic unwork of art.
        </p>
      </details>
      <p>
        <a
          href="https://raw.githubusercontent.com/fdch/specexp/master/paper/hally-paper.pdf"
          >a spectral experience: self convolution and face tracking. 2017</a
        >
        - icmc 2018 (acepted but not presented)
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          “hearing the self: a spectral experience” (aka hally) is an
          interactive, immersive, multimedia, and robotic installation,
          simulating the process by which the human brain per- ceives the world.
          this paper explores the role of both sound and image in the definition
          of the self this installation brings forth. we briefly explore
          previous approaches to image soni- fication, and propose that through
          video-based convolution new conceptualizations of the self can arise.
          further, this expression of the self is neither centered on the human
          par- ticipant nor on the socially constructed notions of the self, but
          on nonhuman aspects such as the reflection and capture of light, or
          the technological array of the installation as such. the participant’s
          exploration within this spectrality results in an uncanny and playful
          experience.
        </p>
      </details>
      <p>
        <a
          href="https://raw.githubusercontent.com/fdch/marelle_response/master/tex/for_young_ears.pdf"
          >for young years: a response to elsa justel's marelle. 2017</a
        >
        - [open space magazine - issue 21](http://the-open-space.org/issue-21/
      </p>
      <details>
        <summary>abstract</summary>
        <p>
          a black box room packed with a rather large audience surrounded by 16
          genelec speakers set as two rings of 8, with an elevation of about 1.5
          meters. i arrived just in time for the concert and there were barely
          any seats left. i sat at the back with my head right behind speaker
          no. 5 –a quite ‘bad’ location to listen to spatialized music inside a
          dome. i had the old fear one might encounter in an electroacoustic
          concert if one is not sitting around the ‘sweet spot’.1 despite my
          fears –and this is why i am writing this–, dr. justel started playing
          marelle2 and i could listen to her music inside the entire space in
          front of me. how did she achieve a complete multidimensional image
          that can be grasped from a point other than the center of the
          listening space? to what extent is this composition inherent to a
          particular spatial distribution? how can i go about showing this? this
          text is my response to her use of space.
        </p>
      </details>
    </main>
  </body>
</html>
